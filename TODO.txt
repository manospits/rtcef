Framework for online hyper-parameter optimisation of offline trained models.

The framework should accomplish the following:
	- save data from the input stream according to some methodology (e.g., exponential deckay, last k buckets etc)
	- the forecasting model should run uninterrupted (it should interrupt only when the model is updated with a new one)
	- the forecasting engine should produce an output stream, and a metrics time series
	- using the metrics time series and some policy a service should decide whether there is a need
	  for re-training re-hyperparameter optimisation
	- subject to the need for retraining/re hyperparameter optimisation a service should ask
	  a model creator to provide metrics for models (when optimisation) or a retrained model (re-training)
	- the models should be sent the engine so that the engine updates the model with the latest version

:

 + design architecture that accomplishes the above
 	+ engine    : performs cef
 	+ collector : collects data
 	+ observer  : monitors performance of engine
 	+ factory   : creates models
 	+ optimiser : schedules optimisation training

 + kafka
 	+ setup kafka
 	+ create scripts for:
 		+ topic creation
 		+ topic deletion

 + create a generic service class that:
      	+ reads a configuration file for kafka settings (server location etc) and starts connection to the broker
 	+ creates producers and consumers according to a configuration file (e.g., the factory
 	  should have a producer for sending messages with updated models and a producer for
 	  messages with model scores during optimisation)
 	+ the producers and consumers should read also a message schema in case fast serialization/deserialization
 	  (e.g., avro) is needed.
 	+ release resources that are not service specific.
 	+ reads service specific configuration paramaters (e.g., for the collector service which policy should be used)
 	+ saves logs

 + the collector should do the following:
 	+ consume the input stream in sync with the engine (i.e., we do not want the collect to consume the input stream
 	  faster than the engine)
 	+ save buckets of some size (temporal, count)
 	+ according to some policy use the saved buckets
 	  to send dataset version information to the factory (e.g., version:1, first_bucket:1, last_bucket 10)
 	+ delete buckets that are not used anymore:
 		+ this means that the factory has assembled a dataset from these buckets
 		+ the buckets should not be deleted if the dataset has not been assembled in the factory or
 		  if the factory is in the process of assembling the buckets
 	+ on termination delete any leftover buckets

 + the factory should do the following:
 	+ update the latest dataset to be used for retraining/optimisation (delete also those that are not used)
 		+ the dataset should not be updated if an optimisation process has started i.e.,
    	         if an optimisation process started with dataset version 1 it should finish with that version.
 	+ send to collector that a dataset has been assembled (sync)
 	+ communicate with the optimiser service via a message protocol
 	  that includes the following message types:
	  	+ optimisation init
 	  	+ optimisation step (request/result)
	  	+ optimisation end (result)
 	  	+ retrain instruction
 	+ using a python wrapper of wayeb train, save, and test models
	+ all models should be saved until they are not needed
 	+ sends model versions
 	+ release resources

 + the optimiser service should have:
 	+ a generic optimisation wrapper
 		+ skopt wrapper
 	+ read messages from the observer
 	+ send messages for retraining to factory
 	+ begin an optimisation procedure by initialising
 	  a message exchange with the factory (see above)
 	+ finish the optimisation procedure by sending
 	  which model was the best

 + the observer should:
    + read scores of the engine
    + according to some policy ask optimiser to start retraining - reoptimise

 + replayer:
    + replay the dataset from a file and feed it to the framework's input topic

 + the engine should:
    + run the model continuously
    + send current position to collector (sync)
    + create avro serializer/deserializer classes
    + update the model
    + the above will be cleaner if they are performed through scala itself and not through
      wrapping
    + the engine should stop when optimisation starts, otherwise it will process the whole stream

EXTRAS:
 + change message (de)serialization to avro for bigger throughput (done)
	+ this means that all messages should have an avro schema defined.

 - create extra collection policies for the collector to be tested
 	+ last k buckets
 	- score based

 - create extra train/optimise selection policies for the observer
 	+ difference between two reports
 	+ trend analysis
 	- drift paper

 - consider elasticSearch/influx in the observer

 - consider using a distributed db for sharing data
  of big size between services (e.g., models, buckets etc)

EXPERIMENTS
	(Wayeb)
	 - Evaluate accuracy with different train/opt selection policies and different dataset collection policies
	 - Evaluate performance of framework and wayeb by multiplying messages
	 - ideally more models should be considered. (???)

	(framework)
	 - Evaluate accuracy with different train/opt selection policies and different dataset collection policies for many models
	 - Stress test with different models
